{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d4723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import ollama  # LLaMA model API\n",
    "import re\n",
    "from tqdm import tqdm  # For progress bars\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  # For parallel processing\n",
    "from gnews import GNews  # Import the GNews package\n",
    "from pytz import UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b84680",
   "metadata": {},
   "source": [
    "### Downloading historic asset price from yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82397f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Historical Prices\n",
    "def fetch_all_historical_prices(asset_symbol, start_date, end_date):\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            asset_symbol,\n",
    "            start=start_date.strftime('%Y-%m-%d'),\n",
    "            end=end_date.strftime('%Y-%m-%d'),\n",
    "            progress=False\n",
    "        )\n",
    "        if data.empty:\n",
    "            raise ValueError(f\"No data found for {asset_symbol} between {start_date} and {end_date}.\")\n",
    "        data = data[['Close']].rename(columns={'Close': asset_symbol})\n",
    "        data.columns = [asset_symbol]\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {asset_symbol}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039e8e9",
   "metadata": {},
   "source": [
    "### Downloading historic asset news from Gnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fe25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch News using GNews\n",
    "def fetch_all_google_news(query, start_date, end_date):\n",
    "    gnews = GNews(language='en', country='US', max_results=5)  # Limit to top 5 headlines\n",
    "    all_news_list = []\n",
    "\n",
    "    # Generate date ranges\n",
    "    date_ranges = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "    for date in tqdm(date_ranges, desc=\"Fetching news data\"):\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        try:\n",
    "            # Fetch articles for the specific date\n",
    "            articles = gnews.get_news(f\"{query} after:{date_str} before:{(date + timedelta(days=1)).strftime('%Y-%m-%d')}\")\n",
    "            if articles:\n",
    "                unique_titles = [article.get('title', 'No Title') for article in articles[:5]]  # Top 5 headlines\n",
    "                news_content = \" \".join(unique_titles)\n",
    "                news_content = news_content[:500]  # Limit news content to 500 characters\n",
    "                all_news_list.append({\n",
    "                    \"Date\": date,\n",
    "                    \"News\": news_content\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching news for {date_str}: {e}\")\n",
    "\n",
    "    # Create DataFrame from the list\n",
    "    all_news = pd.DataFrame(all_news_list)\n",
    "    all_news.drop_duplicates(subset=[\"Date\"], inplace=True)\n",
    "    all_news.set_index('Date', inplace=True)\n",
    "    return all_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d4548",
   "metadata": {},
   "source": [
    "### Load data locally or Fetch Data from yfinance & Gnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ae50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or Fetch Data\n",
    "def load_or_fetch_data(asset_symbol, query, start_date, end_date):\n",
    "    # Fetch or load historical prices\n",
    "    if not os.path.exists(f\"{asset_symbol}_historical_prices.csv\"):\n",
    "        print(\"Fetching historical prices...\")\n",
    "        historical_prices = fetch_all_historical_prices(asset_symbol, start_date, end_date)\n",
    "        historical_prices.to_csv(f\"{asset_symbol}_historical_prices.csv\", index=True)\n",
    "        print(f\"Historical prices saved to '{asset_symbol}_historical_prices.csv'.\")\n",
    "    else:\n",
    "        print(\"Loading existing historical prices...\")\n",
    "        historical_prices = pd.read_csv(\n",
    "            f\"{asset_symbol}_historical_prices.csv\",\n",
    "            parse_dates=[\"Date\"],\n",
    "            index_col=\"Date\"\n",
    "        )\n",
    "\n",
    "        # Ensure the correct column name\n",
    "        if asset_symbol not in historical_prices.columns:\n",
    "            raise ValueError(f\"The expected column '{asset_symbol}' was not found in '{asset_symbol}_historical_prices.csv'.\")\n",
    "\n",
    "        historical_prices = historical_prices[[asset_symbol]]  # Select the column for the asset\n",
    "\n",
    "    # Fetch or load news data\n",
    "    if not os.path.exists(f\"{asset_symbol}_news_data.csv\"):\n",
    "        print(\"Fetching news data...\")\n",
    "        news_data = fetch_all_google_news(query, start_date, end_date)\n",
    "        news_data.to_csv(f\"{asset_symbol}_news_data.csv\", index=True)\n",
    "        print(f\"News data saved to '{asset_symbol}_news_data.csv'.\")\n",
    "    else:\n",
    "        print(\"Loading existing news data...\")\n",
    "        news_data = pd.read_csv(\n",
    "            f\"{asset_symbol}_news_data.csv\",\n",
    "            parse_dates=[\"Date\"],\n",
    "            index_col=\"Date\"\n",
    "        )\n",
    "\n",
    "    return historical_prices, news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8476dd90-5ade-4063-a07a-17205a89c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the date using index difference.\n",
    "def LastMarketOpen_DateDiff(df, curr_date, delta):\n",
    "    '''Index of the dataframe is pandas datetime format. In case date is a column in dataframe use timedelta toget the difference.'''\n",
    "    curr_date_index = df.index.get_loc(curr_date)\n",
    "    final_date = pd.to_datetime(df.iloc[curr_date_index+(delta)].name)\n",
    "    return (final_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5df69a",
   "metadata": {},
   "source": [
    "### Given one slice of input data making n-simulated predictions.\n",
    "- Instead of taking past m days window size, here we will take past m indexes because some stock exchanges remain closed on holidays.\n",
    "- News data for each market open day should be the cummulation of all news which came after the last market day till the current day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9021727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Next Day's Price with LLaMA (Probabilistic) including news\n",
    "def predict_next_price_probabilistic(\n",
    "    asset_symbol,\n",
    "    current_date,\n",
    "    historical_prices,\n",
    "    news_data,\n",
    "    window_size,\n",
    "    n_simulations,\n",
    "    quantiles=(0.05, 0.5, 0.95)\n",
    "):\n",
    "\n",
    "    # current_date_index = historical_prices.index.get_loc(current_date)\n",
    "    # start_date = pd.to_datetime(historical_prices.iloc[current_date_index-(window_size - 1)].name)     # current_date - timedelta(days=window_size - 1)\n",
    "    start_date = LastMarketOpen_DateDiff(historical_prices, current_date, -(window_size - 1))\n",
    "    historical_window = historical_prices.loc[start_date:current_date].dropna().values.flatten()\n",
    "\n",
    "    if len(historical_window) < window_size:\n",
    "        print(f\"Insufficient data for prediction on {current_date.date()}.\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    historical_prices_str = \", \".join(f\"{x:.2f}\" for x in historical_window)\n",
    "    predictions = []\n",
    "\n",
    "    # Get news data from the last market open date to current_date\n",
    "    prev_hp_date = LastMarketOpen_DateDiff(historical_prices, current_date, -1)\n",
    "    # curr_dt_index = news_data.index.get_loc(current_date)\n",
    "    # prev_dt_index = news_data.index.get_loc(LastMarketOpen_DateDiff(historical_prices, current_date, -1))\n",
    "\n",
    "    historical_dates = historical_prices.loc[start_date:current_date].dropna().index\n",
    "    for date in historical_dates:\n",
    "        if date not in news_data.index:\n",
    "            news_data.loc[date]=\"No significant news.\" \n",
    "    news_window = news_data.loc[historical_dates, 'News'].dropna().values.flatten()\n",
    "    news_contents = \", \".join(f\"({x})\" for x in news_window)\n",
    "    news_current = news_data.loc[current_date, 'News'] if current_date in news_data.index else \"No significant news.\"\n",
    "    \n",
    "    History_E1 = \", \".join(f\"{x:.2f}\" for x in historical_window[:window_size-5])\n",
    "    History_E2 = \", \".join(f\"{x:.2f}\" for x in historical_window[1:window_size-4])\n",
    "    History_E3 = \", \".join(f\"{x:.2f}\" for x in historical_window[2:window_size-3])\n",
    "    History_E4 = \", \".join(f\"{x:.2f}\" for x in historical_window[3:window_size-2])\n",
    "    History_E5 = \", \".join(f\"{x:.2f}\" for x in historical_window[4:window_size-1])\n",
    "    History_O = \", \".join(f\"{x:.2f}\" for x in historical_window[5:window_size])\n",
    "    \n",
    "    print(\n",
    "        f\"Following examples shows past {window_size-5} days historic prices list, recent news related to {asset_symbol} as input and next price as their corresponding output:\\n\"\n",
    "        f\"Example 1: </input> [Prices:[{History_E1}], News:{news_window[-5]}], </output> {historical_window[-5]}\\n\"\n",
    "        f\"Example 2: </input> [Prices:[{History_E2}], News:{news_window[-4]}], </output> {historical_window[-4]}\\n\"\n",
    "        f\"Example 3: </input> [Prices:[{History_E3}], News:{news_window[-3]}], </output> {historical_window[-3]}\\n\"\n",
    "        f\"Example 4: </input> [Prices:[{History_E4}], News:{news_window[-2]}], </output> {historical_window[-2]}\\n\"\n",
    "        f\"Example 5: </input> [Prices:[{History_E5}], News:{news_window[-1]}], </output> {historical_window[-1]}\\n\\n\"\n",
    "        f\"Based on the insights learned from the above examples, return the next price for {asset_symbol} using the following input:\\n\"\n",
    "        f\"</input> [Prices:[{History_O}], News:{news_current}]\\n\\n\"\n",
    "        f\"Make sure to capture the effect of Prices and News for predicting the output\\n\"\n",
    "        f\"Provide your output as a single number (e.g., 38500.00). Do not include any text other than the number.\"\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        f\"Following examples shows past {window_size-5} days historic prices list, recent news related to {asset_symbol} as input and next price as their corresponding output:\\n\"\n",
    "        f\"Example 1: </input> [Prices:[{History_E1}], News:{news_window[-5]}], </output> {historical_window[-5]}\\n\"\n",
    "        f\"Example 2: </input> [Prices:[{History_E2}], News:{news_window[-4]}], </output> {historical_window[-4]}\\n\"\n",
    "        f\"Example 3: </input> [Prices:[{History_E3}], News:{news_window[-3]}], </output> {historical_window[-3]}\\n\"\n",
    "        f\"Example 4: </input> [Prices:[{History_E4}], News:{news_window[-2]}], </output> {historical_window[-2]}\\n\"\n",
    "        f\"Example 5: </input> [Prices:[{History_E5}], News:{news_window[-1]}], </output> {historical_window[-1]}\\n\\n\"\n",
    "        f\"Based on the insights learned from the above examples, return the next price for {asset_symbol} using the following input:\\n\"\n",
    "        f\"</input> [Prices:[{History_O}], News:{news_current}]\\n\\n\"\n",
    "        f\"Make sure to capture the effect of Prices and News for predicting the output\\n\"\n",
    "        f\"Provide your output as a single number (e.g., 38500.00). Do not include any text other than the number.\"\n",
    "    )\n",
    "\n",
    "    def run_simulation(_):\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=\"llama3.1\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a financial forecasting assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            response_content = response[\"message\"][\"content\"]\n",
    "            match = re.search(r\"[\\$]?[0-9,]+\\.?[0-9]*\", response_content)\n",
    "            if match:\n",
    "                return float(match.group().replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "        except Exception as e:\n",
    "            print(f\"LLaMA simulation failed: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "    max_workers = min(10, n_simulations)  # Limit number of threads\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(run_simulation, _) for _ in range(n_simulations)]\n",
    "        for future in tqdm(\n",
    "            as_completed(futures),\n",
    "            total=n_simulations,\n",
    "            desc=f\"Simulating {n_simulations} predictions for {current_date.date()}\"\n",
    "        ):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                predictions.append(result)\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        print(f\"No valid predictions generated for {current_date}.\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    # Calculate quantiles\n",
    "    quantile_values = np.nanquantile(predictions, quantiles)\n",
    "    return quantile_values[0], quantile_values[1], quantile_values[2], predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb9de0",
   "metadata": {},
   "source": [
    "### Making predictions on a roling window from start_date to end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "638cdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Predictions with Probabilistic Forecasting including news\n",
    "def rolling_window_price_predictions_probabilistic(\n",
    "    asset_symbol,\n",
    "    historical_prices,\n",
    "    news_data,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    window_size,\n",
    "    n_simulations\n",
    "):\n",
    "    historical_prices.index = pd.to_datetime(historical_prices.index).normalize().tz_localize(None)\n",
    "    news_data.index = pd.to_datetime(news_data.index).normalize()\n",
    "    # Adjust start_date to ensure enough data for the window\n",
    "    earliest_date = historical_prices.index[0 + window_size - 1]      #+ timedelta(days=window_size - 1)\n",
    "    print(earliest_date)\n",
    "    start_date = max(start_date, earliest_date)\n",
    "    current_date = start_date\n",
    "    end_date = min(end_date, historical_prices.index[-2])  # Ensure end_date is within available data  # - timedelta(days=1)\n",
    "\n",
    "    predictions = []\n",
    "    raw_prediction_list = []\n",
    "    iteration = 0\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        current_date_norm = pd.to_datetime(current_date).normalize()\n",
    "\n",
    "        # Calculate the start date of the window\n",
    "        # window_start_date = current_date_norm - timedelta(days=window_size - 1)\n",
    "        window_start_date = LastMarketOpen_DateDiff(historical_prices, current_date_norm, -(window_size - 1))\n",
    "\n",
    "        # Check if the window is within the data range\n",
    "        if window_start_date < historical_prices.index[0]:\n",
    "            print(f\"Not enough historical data to create a window for {current_date_norm.date()}. Skipping.\")\n",
    "            # current_date += timedelta(days=1)\n",
    "            current_date = LastMarketOpen_DateDiff(historical_prices, current_date, 1)\n",
    "            continue\n",
    "\n",
    "        low, median, high, raw_predictions = predict_next_price_probabilistic(\n",
    "            asset_symbol,\n",
    "            current_date_norm,\n",
    "            historical_prices,\n",
    "            news_data,\n",
    "            window_size,\n",
    "            n_simulations\n",
    "        )\n",
    "\n",
    "        # Accumulating raw output for all simulations\n",
    "        raw_prediction_list.append(raw_predictions)\n",
    "\n",
    "        # Get the actual price for the next day (the day after current_date)\n",
    "        # next_date = current_date_norm + timedelta(days=1)\n",
    "        next_date = LastMarketOpen_DateDiff(historical_prices, current_date_norm, 1)\n",
    "        if next_date in historical_prices.index:\n",
    "            actual_price = historical_prices.loc[next_date, asset_symbol]\n",
    "        else:\n",
    "            print(f\"No actual price available for {next_date.date()}. Skipping.\")\n",
    "            current_date = LastMarketOpen_DateDiff(historical_prices, current_date, 1)\n",
    "            continue\n",
    "\n",
    "        if median is not None:\n",
    "            predictions.append(\n",
    "                (next_date, low, median, high, actual_price)\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No prediction available for {current_date_norm.date()}.\")\n",
    "\n",
    "        current_date = LastMarketOpen_DateDiff(historical_prices, current_date, 1)\n",
    "\n",
    "        iteration += 1\n",
    "        if iteration%5 == 0:\n",
    "            # Saving pedictions after every 30 steps (days)\n",
    "            predictions_df = pd.DataFrame(\n",
    "                    predictions,\n",
    "                    columns=[\"Date\", \"Low_Prediction\", \"Median_Prediction\", \"High_Prediction\", \"Actual_Price\"]\n",
    "                )\n",
    "            predictions_df.to_csv('predictions_partial.csv', index=False)\n",
    "\n",
    "            # Saving raw simulation output after every 30 steps (days)\n",
    "            raw_output_df = pd.DataFrame(raw_prediction_list,\n",
    "                                         columns = [f\"out_{i}\" for i in range(n_simulations)])\n",
    "            raw_output_df[\"Date\"] = predictions_df[\"Date\"]\n",
    "            raw_output_df.to_csv('raw_output_partial.csv', index=False)\n",
    "\n",
    "    # Final prediction df.\n",
    "    predictions_df = pd.DataFrame(\n",
    "        predictions,\n",
    "        columns=[\"Date\", \"Low_Prediction\", \"Median_Prediction\", \"High_Prediction\", \"Actual_Price\"]\n",
    "    )\n",
    "    # Final raw output df\n",
    "    raw_output_df = pd.DataFrame(raw_prediction_list,\n",
    "                                 columns = [f\"out_{i}\" for i in range(n_simulations)])\n",
    "    raw_output_df[\"Date\"] = predictions_df[\"Date\"]\n",
    "    return predictions_df, raw_output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8238a",
   "metadata": {},
   "source": [
    "### Plotting real and predicted prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77059b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Predictions and Metrics\n",
    "def plot_predictions_and_compute_metrics_probabilistic(\n",
    "    predictions_df,\n",
    "    asset_symbol,\n",
    "    save_path=\"predictions_chart.png\"\n",
    "):\n",
    "    predictions_df = predictions_df.dropna(subset=[\"Median_Prediction\", \"Actual_Price\"])\n",
    "    actual_prices = predictions_df[\"Actual_Price\"]\n",
    "    median_predictions = predictions_df[\"Median_Prediction\"]\n",
    "\n",
    "    if predictions_df.empty or actual_prices.empty or median_predictions.empty:\n",
    "        print(\"No predictions to plot or compute metrics.\")\n",
    "        return None, None\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(actual_prices, median_predictions))\n",
    "    r2 = r2_score(actual_prices, median_predictions)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        predictions_df[\"Date\"],\n",
    "        actual_prices,\n",
    "        label=\"Actual Prices\",\n",
    "        color=\"blue\",\n",
    "        linestyle='-'\n",
    "    )\n",
    "    plt.plot(\n",
    "        predictions_df[\"Date\"],\n",
    "        median_predictions,\n",
    "        label=\"Median Predictions\",\n",
    "        color=\"red\",\n",
    "        linestyle='--'\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        predictions_df[\"Date\"],\n",
    "        predictions_df[\"Low_Prediction\"],\n",
    "        predictions_df[\"High_Prediction\"],\n",
    "        color='gray',\n",
    "        alpha=0.3,\n",
    "        label=\"Prediction Range (1%-99%)\"\n",
    "    )\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(\"Probabilistic Forecasting: Predicted vs Actual Prices with News Influence\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # plt.ylim([100,250])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot as a transparent PNG\n",
    "    plt.savefig(save_path, transparent=True, dpi=300)\n",
    "    print(f\"Chart saved to {save_path} (transparent background).\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"Out-of-Sample R2: {r2:.4f}\")\n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26816015-5538-4815-8bfd-9b34df908e06",
   "metadata": {},
   "source": [
    "### Execution\n",
    "#### Assumptions:\n",
    "- Complete data for all  market data is available from start_date to end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5548b30-cf85-4a7d-a1b3-7faeef8b9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assets = ['CBU','^GDAXI', '^GSPC', 'GOOG', 'XLE', '^STOXX', '^N225', '^BSESN', '^FTSE', 'TXGE', 'BTC-USD']\n",
    "# news_query = ['Community Financial System Inc. stock news', 'DAX PERFORMANCE-INDEX news', 'S&P 500 news', \n",
    "#              'Google, Alphabet Inc. stock news', 'Energy Select Sector SPDR Fund news', 'STOXX Europe 600 news',\n",
    "#              'Nikkei 225 news', 'FTSE 100 Index news', 'Texas Gulf Energy, Incorporated (TXGE) news', 'Bitcoin news']\n",
    "\n",
    "assets = ['GOOG']\n",
    "news_query = ['Google, Alphabet Inc. stock price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "533f160b-e230-4fc2-8481-8765b80e71e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01 00:00:00\n",
      "2024-11-30 00:00:00\n",
      "Loading existing historical prices...\n",
      "Loading existing news data...\n",
      "2024-01-23 00:00:00\n",
      "Following examples shows past 10 days historic prices list, recent news related to GOOG as input and next price as their corresponding output:\n",
      "Example 1: </input> [Prices:[139.06, 139.86, 137.55, 136.90, 140.03, 142.05, 143.29, 143.16, 143.72, 143.56], News:How To Invest In Magnificent Seven Stocks Like Nvidia In 2024 - Investor's Business Daily Sundar Pichai is taking a leaf out of Mark Zuckerberg’s book and warns Google staff ‘ambitious goals’ can only be met with job cuts - Fortune 2 Top Growth Stocks to Buy Hand Over Fist Before the Nasdaq Soars Higher in 2024 - The Motley Fool Google CEO says more job cuts are needed in 2024 in order to reach ‘ambitious goals’ - CNBC Apple Stock vs. Microsoft Stock: Which Is Better? - TheStreet], </output> 142.37841796875\n",
      "Example 2: </input> [Prices:[139.86, 137.55, 136.90, 140.03, 142.05, 143.29, 143.16, 143.72, 143.56, 142.38], News:Stock market today: Dow, S&P 500 hit record highs as tech stocks soar - Yahoo Finance Google and AT&T join $155 million AST SpaceMobile investment - SpaceNews How To Invest In Magnificent Seven Stocks Like Nvidia In 2024 - Investor's Business Daily 2 Top Growth Stocks to Buy Hand Over Fist Before the Nasdaq Soars Higher in 2024 - The Motley Fool Google CEO’s internal memo warns of further layoffs ahead - CNN], </output> 144.4709014892578\n",
      "Example 3: </input> [Prices:[137.55, 136.90, 140.03, 142.05, 143.29, 143.16, 143.72, 143.56, 142.38, 144.47], News:Stock market today: Dow, S&P 500 hit record highs as tech stocks soar - Yahoo Finance Google and AT&T join $155 million AST SpaceMobile investment - SpaceNews Tesla and Elon Musk will rock markets this week - TheStreet 20 High-Yield Dividend Stocks for December 2024 - The Motley Fool Billionaire Bill Ackman Owns $1.8 Billion of This AI Stock -- and 38 Wall Street Analysts Recommend Buying It Right Now - Yahoo Finance], </output> 147.44021606445312\n",
      "Example 4: </input> [Prices:[136.90, 140.03, 142.05, 143.29, 143.16, 143.72, 143.56, 142.38, 144.47, 147.44], News:These Seven Tech Stocks Are Driving the Market - The New York Times Meta Stock Forecast: 2024 Could Be Mark Zuckerberg's Trillion-Dollar Year - Investor's Business Daily Why These 3 Stocks Are My Top Picks For 2024 - Seeking Alpha Top analyst unveils new AMD stock forecast ahead of earnings - TheStreet Stock market today: S&P 500 vaults to fresh high while earnings drag on Dow - Yahoo Finance], </output> 147.18118286132812\n",
      "Example 5: </input> [Prices:[140.03, 142.05, 143.29, 143.16, 143.72, 143.56, 142.38, 144.47, 147.44, 147.18], News:Stock market today: Tech stocks lead as S&P 500 logs another record close - Yahoo Finance My Top 3 Growth Stocks in 2024 - The Motley Fool Top analyst unveils new AMD stock forecast ahead of earnings - TheStreet Stock market today: S&P 500 vaults to fresh high while earnings drag on Dow - Yahoo Finance Google Earnings Preview: 5% Stock Price Move Expected - tastylive], </output> 148.14768981933594\n",
      "\n",
      "Based on the insights learned from the above examples, return the next price for GOOG using the following input:\n",
      "</input> [Prices:[142.05, 143.29, 143.16, 143.72, 143.56, 142.38, 144.47, 147.44, 147.18, 148.15], News:Stock market today: Tech stocks lead as S&P 500 logs another record close - Yahoo Finance My Top 3 Growth Stocks in 2024 - The Motley Fool Top analyst unveils new AMD stock forecast ahead of earnings - TheStreet Stock market today: S&P 500 vaults to fresh high while earnings drag on Dow - Yahoo Finance Google Earnings Preview: 5% Stock Price Move Expected - tastylive]\n",
      "\n",
      "Make sure to capture the effect of Prices and News for predicting the output\n",
      "Provide your output as a single number (e.g., 38500.00). Do not include any text other than the number.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating 100 predictions for 2024-01-23:   0%|        | 0/100 [00:03<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Execution\n",
    "if __name__ == \"__main__\":\n",
    "    for index, asset in enumerate(assets):\n",
    "        asset_symbol = asset\n",
    "        query = news_query[index]\n",
    "        # start_date = pd.to_datetime(pd.read_csv('predictions_partial.csv')['Date'][-1])\n",
    "        start_date = pd.to_datetime('2024-01-01')  # Adjusted to 2023 as future data may not be available\n",
    "        end_date = pd.to_datetime('2024-11-30')\n",
    "        print(start_date)\n",
    "        print(end_date)\n",
    "        window_size = 15\n",
    "        n_simulations = 100  # Adjust this value as needed\n",
    "\n",
    "        # Import or Fetch Data\n",
    "        historical_prices, news_data = load_or_fetch_data(asset_symbol, query, start_date, end_date)\n",
    "\n",
    "        # Rolling Predictions with Probabilistic Forecasting\n",
    "        predictions_df, raw_output = rolling_window_price_predictions_probabilistic(\n",
    "            asset_symbol,\n",
    "            historical_prices,\n",
    "            news_data,\n",
    "            start_date,\n",
    "            end_date,\n",
    "            window_size,\n",
    "            n_simulations\n",
    "        )\n",
    "        # Saving results to a file.\n",
    "        predictions_df.to_csv(f'{asset_symbol}_predictions_full_p3.csv')\n",
    "        raw_output.to_csv(f'{asset_symbol}_raw_output_p3.csv')\n",
    "\n",
    "        # Plot and Evaluate Metrics\n",
    "        rmse, r2 = plot_predictions_and_compute_metrics_probabilistic(predictions_df, asset_symbol, f\"{asset_symbol}_predictions_chart_p3.png\")\n",
    "\n",
    "        if rmse is not None and r2 is not None:\n",
    "            print(\"\\nFinal Metrics:\")\n",
    "            print(f\"RMSE: {rmse:.4f}\")\n",
    "            print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807433af-d1cf-460f-8df4-32e72a3ce6fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510fd82-3934-4394-b6e0-34308aadf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(f'{asset_symbol}_predictions_full_3.3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1ad4a-5c78-44ea-89d6-70fbf0b0d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, r2 = plot_predictions_and_compute_metrics_probabilistic(predictions_df, asset_symbol, f\"{asset_symbol}_predictions_chart_3.3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b669d-3608-4b3b-b815-99b3eb225f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3d114b1-15db-4480-9854-6d9dd139b202",
   "metadata": {},
   "source": [
    "### Test to check if ollama is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e906589-8d35-428e-b4e6-9df91b85e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(\n",
    "    model=\"llama3.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a financial forecasting assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is square of 2\"}\n",
    "    ]\n",
    ")\n",
    "response_content = response[\"message\"][\"content\"]\n",
    "match = re.search(r\"[\\$]?[0-9,]+\\.?[0-9]*\", response_content)\n",
    "print(response_content)\n",
    "if match:\n",
    "    print (float(match.group().replace(\",\", \"\").replace(\"$\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c8375-e8fb-47a6-a040-3292d09a409b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56fbe8-83d5-4631-8fa2-fb9366d8b4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669af34-959d-42a8-bc98-6a1f61e97015",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415344a3-0b9a-4fe9-b31a-b19c934f4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_scaling = (predictions_df.iloc[:,1:].values>1000)*0.01 + (predictions_df.iloc[:,1:].values<1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc14e22-184e-4c04-af66-6ec3659a05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ff274-ee8b-422b-9a6f-2a47115fd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_values = predictions_df.iloc[:,1:].values * correction_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7dd0af-0436-47ec-8266-5b51b2c50298",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df = pd.DataFrame(data = correct_values, columns = predictions_df.columns[1:])\n",
    "correct_df['Date'] = predictions_df['Date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cbfda-cfd8-47a8-9dea-3912b223db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, r2 = plot_predictions_and_compute_metrics_probabilistic(correct_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909760bd-c296-4b5c-b490-a988345432cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "4%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0bbd7-e9ed-479e-83ee-43be3236e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
